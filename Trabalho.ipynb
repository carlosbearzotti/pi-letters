{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1413bde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c27ecf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imagens carregadas: 10000\n"
     ]
    }
   ],
   "source": [
    "data_dir = r\"imagens\\indie\\pi\\dataset\\v20220930\"\n",
    "img_size = 16\n",
    "\n",
    "X, y = [], []\n",
    "\n",
    "for root, dirs, files in os.walk(data_dir):\n",
    "    pasta_vogal = os.path.basename(os.path.dirname(root))\n",
    "    letra = pasta_vogal[0].lower() if pasta_vogal else None\n",
    "    if letra in ['a','e','i','o','u']:\n",
    "        for file in files:\n",
    "            if file.lower().endswith(('.png','.jpg','.jpeg')):\n",
    "                img_path = os.path.join(root, file)\n",
    "                img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "                img = cv2.resize(img, (img_size, img_size))\n",
    "                X.append(img.flatten())\n",
    "                y.append(1 if letra == 'i' else 0)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(\"Total de imagens carregadas:\", len(X))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "055e0f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treinando e avaliando KNN...\n",
      "Treinando e avaliando MLP...\n",
      "     Acurácia  Precision    Recall        F1\n",
      "KNN    0.9696   0.894557  0.961500  0.926787\n",
      "MLP    0.9538   0.890172  0.878474  0.883484\n",
      "Resultados da avaliação salvos em avaliacao_modelos.npz e avaliacao_modelos.csv\n"
     ]
    }
   ],
   "source": [
    "# Configurações\n",
    "n_splits = 3\n",
    "random_state = 42\n",
    "\n",
    "def evaluate_model(model, X, y, kf):\n",
    "    accs, precs, recs, f1s = [], [], [], []\n",
    "    for train_idx, test_idx in kf.split(X, y):\n",
    "        model.fit(X[train_idx], y[train_idx])\n",
    "        preds = model.predict(X[test_idx])\n",
    "        accs.append(accuracy_score(y[test_idx], preds))\n",
    "        precs.append(precision_score(y[test_idx], preds))\n",
    "        recs.append(recall_score(y[test_idx], preds))\n",
    "        f1s.append(f1_score(y[test_idx], preds))\n",
    "    return np.mean(accs), np.mean(precs), np.mean(recs), np.mean(f1s)\n",
    "\n",
    "kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "# Criar modelos (removendo SVM)\n",
    "model_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "model_mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=200)\n",
    "\n",
    "# Avaliar modelos\n",
    "results = {}\n",
    "for name, model in [(\"KNN\", model_knn), (\"MLP\", model_mlp)]:\n",
    "    print(f\"Treinando e avaliando {name}...\")\n",
    "    acc, prec, rec, f1 = evaluate_model(model, X, y, kf)\n",
    "    results[name] = (acc, prec, rec, f1)\n",
    "    # Salvar modelo final\n",
    "    dump(model, f\"{name}_final_model.pkl\")\n",
    "\n",
    "# Exibir resultados\n",
    "df = pd.DataFrame(results, index=[\"Acurácia\", \"Precision\", \"Recall\", \"F1\"]).T\n",
    "print(df)\n",
    "\n",
    "# -----------------------------\n",
    "# Salvar resultados para futuras execuções\n",
    "# -----------------------------\n",
    "\n",
    "# Salvar em NPZ (Python)\n",
    "np.savez(\"avaliacao_modelos.npz\", **results)\n",
    "\n",
    "# Salvar em CSV (legível)\n",
    "df.to_csv(\"avaliacao_modelos.csv\")\n",
    "\n",
    "print(\"Resultados da avaliação salvos em avaliacao_modelos.npz e avaliacao_modelos.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c597e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removido pela questão do metódo SVM (Support Vector Machine) ser lento que só uma porra e pior que o kNN (k-Nearest Neighbors)\n",
    "\n",
    "# Configurações\n",
    "# n_splits = 3\n",
    "# random_state = 42\n",
    "\n",
    "# def evaluate_model(model, X, y, kf):\n",
    "#     accs, precs, recs, f1s = [], [], [], []\n",
    "#     for train_idx, test_idx in kf.split(X, y):\n",
    "#         model.fit(X[train_idx], y[train_idx])\n",
    "#         preds = model.predict(X[test_idx])\n",
    "#         accs.append(accuracy_score(y[test_idx], preds))\n",
    "#         precs.append(precision_score(y[test_idx], preds))\n",
    "#         recs.append(recall_score(y[test_idx], preds))\n",
    "#         f1s.append(f1_score(y[test_idx], preds))\n",
    "#     return np.mean(accs), np.mean(precs), np.mean(recs), np.mean(f1s)\n",
    "\n",
    "# kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "# # Criar modelos\n",
    "# model_knn = KNeighborsClassifier(n_neighbors=3)\n",
    "# model_svm = SVC(kernel='linear')\n",
    "# model_mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=200)\n",
    "\n",
    "# # Avaliar modelos\n",
    "# results = {}\n",
    "# for name, model in [(\"KNN\", model_knn), (\"SVM\", model_svm), (\"MLP\", model_mlp)]:\n",
    "#     print(f\"Treinando e avaliando {name}...\")\n",
    "#     acc, prec, rec, f1 = evaluate_model(model, X, y, kf)\n",
    "#     results[name] = (acc, prec, rec, f1)\n",
    "#     # Salvar modelo final\n",
    "#     dump(model, f\"{name}_final_model.pkl\")\n",
    "\n",
    "# # Exibir resultados\n",
    "\n",
    "# df = pd.DataFrame(results, index=[\"Acurácia\", \"Precision\", \"Recall\", \"F1\"]).T\n",
    "# print(df)\n",
    "\n",
    "# # -----------------------------\n",
    "# # Salvar resultados para futuras execuções\n",
    "# # -----------------------------\n",
    "\n",
    "# # Salvar em NPZ (Python)\n",
    "# np.savez(\"avaliacao_modelos.npz\", **results)\n",
    "\n",
    "# # Salvar em CSV (legível)\n",
    "# df.to_csv(\"avaliacao_modelos.csv\")\n",
    "\n",
    "# print(\"Resultados da avaliação salvos em avaliacao_modelos.npz e avaliacao_modelos.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7ebef59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 0.9695997494170533 0.8945573861863337 0.9615004809907358 0.9267869728533845\n",
      "MLP 0.9537996991060833 0.8901721118656515 0.8784744264504384 0.8834841083593457\n"
     ]
    }
   ],
   "source": [
    "# Carregar resultados salvos\n",
    "data = np.load(\"avaliacao_modelos.npz\")\n",
    "for model in data:\n",
    "    acc, prec, rec, f1 = data[model]\n",
    "    print(model, acc, prec, rec, f1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f901ae",
   "metadata": {},
   "source": [
    "# Melhor Modelo – Comparação\n",
    "\n",
    "Após avaliar os modelos usando cross-validation (3 folds) sobre o dataset de vogais manuscritas para detectar a letra “i”, os resultados foram:\n",
    "\n",
    "Primeira avaliação\n",
    "Modelo  Acurácia    Precision   Recall\tF1\t    Observações\n",
    "KNN\t    0.9874\t    0.9467\t    0.9930\t0.9693\tMais rápido, melhor F1, ideal para uso prático\n",
    "MLP\t    0.9788\t    0.9673\t    0.9255\t0.9459\tBoa precisão, mas treino mais lento\n",
    "SVM\t    0.9705\t    0.9220\t    0.9315\t0.9267\tdemora (25+ minutos), e menor Score\n",
    "\n",
    "Segunda avaliação\n",
    "Modelo  Acurácia    Precision   Recall\tF1\t    Observações\n",
    "KNN    0.9696   0.894557  0.961500  0.926787    Mais rápido, melhor F1, ideal para uso prático pelo menor tempo de treino\n",
    "MLP    0.9538   0.890172  0.878474  0.883484    Boa precisão, treino semelhante em tempo porém menor F1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
